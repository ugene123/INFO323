{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\"> Drexel University </h1>\n",
    "<h2 style = \"text-align:center\"> College of Computing and Informatics</h2>\n",
    "<h2 style = \"text-align:center\">INFO 323: Cloud Computing and Big Data</h2>\n",
    "<h3 style = \"text-align:center\">Assignment 4</h3>\n",
    "<h3 style = \"text-align:center\">Eugene Yakovlev</h3>\n",
    "<h3 style = \"text-align:center\">May 27, 2020</h3>\n",
    "<div style=\"text-align:center; border-style:solid; padding: 10px\">\n",
    "<div style=\"font-weight:bold\">Due Date: Sunday, 05/31/2020</div>\n",
    "This assignment counts for 15% of the final grade\n",
    "</div>\n",
    "\n",
    "### A. Assignment Overview\n",
    "This assignment provides the opportunity for you to practice with Spark data analytics. \n",
    "\n",
    "### B. What to Hand In\n",
    "\t\n",
    "Sumbit a completed this Jupyter notebook. \n",
    "\n",
    "### C. How to Hand In\n",
    "\n",
    "Submit your Jupyter notebook file through the course website in the Blackboard Learn system.\n",
    "\n",
    "### D. When to Hand In\n",
    "\n",
    "1. Submit your assignment no later than 11:59pm in the due date.\n",
    "2. There will be a 10% (absolute value) deduction for each day of lateness, to a maximum of 3 days; assignments will not be accepted beyond that point. Missing work will earn a zero grade.\n",
    "\n",
    "### Note: All the programming must be done in Spark platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Classification in Spark: Run the following cell to import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrameNaFunctions\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Load the weather-samples.csv data into a DataFrame and prints the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- number: integer (nullable = true)\n",
      " |-- air_pressure_9am: double (nullable = true)\n",
      " |-- air_temp_9am: double (nullable = true)\n",
      " |-- avg_wind_direction_9am: double (nullable = true)\n",
      " |-- avg_wind_speed_9am: double (nullable = true)\n",
      " |-- max_wind_direction_9am: double (nullable = true)\n",
      " |-- max_wind_speed_9am: double (nullable = true)\n",
      " |-- rain_accumulation_9am: double (nullable = true)\n",
      " |-- rain_duration_9am: double (nullable = true)\n",
      " |-- relative_humidity_9am: double (nullable = true)\n",
      " |-- relative_humidity_3pm: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load weather-samples.csv df\n",
    "df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"weather-samples.csv\")\n",
    "# print df columns\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Defines the columns in the weather data that will be used for the decision tree classifier (**Done**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumns = ['air_pressure_9am','air_temp_9am','avg_wind_direction_9am','avg_wind_speed_9am',\n",
    "        'max_wind_direction_9am','max_wind_speed_9am','rain_accumulation_9am',\n",
    "        'rain_duration_9am']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Drop unused column. We do not need the \"number\" column in our data, so remove it from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- air_pressure_9am: double (nullable = true)\n",
      " |-- air_temp_9am: double (nullable = true)\n",
      " |-- avg_wind_direction_9am: double (nullable = true)\n",
      " |-- avg_wind_speed_9am: double (nullable = true)\n",
      " |-- max_wind_direction_9am: double (nullable = true)\n",
      " |-- max_wind_speed_9am: double (nullable = true)\n",
      " |-- rain_accumulation_9am: double (nullable = true)\n",
      " |-- rain_duration_9am: double (nullable = true)\n",
      " |-- relative_humidity_9am: double (nullable = true)\n",
      " |-- relative_humidity_3pm: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop \"number\" column\n",
    "df = df.drop(\"number\")\n",
    "# verify \"number\" column is dropped\n",
    "df.printSchema()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Remove all rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values in any of the columns\n",
    "df = df.filter(df.air_pressure_9am.isNotNull())\n",
    "df = df.filter(df.air_temp_9am.isNotNull())\n",
    "df = df.filter(df.avg_wind_direction_9am.isNotNull())\n",
    "df = df.filter(df.avg_wind_speed_9am.isNotNull())\n",
    "df = df.filter(df.max_wind_direction_9am.isNotNull())\n",
    "df = df.filter(df.max_wind_speed_9am.isNotNull())\n",
    "df = df.filter(df.rain_accumulation_9am.isNotNull())\n",
    "df = df.filter(df.rain_duration_9am.isNotNull())\n",
    "df = df.filter(df.relative_humidity_9am.isNotNull())\n",
    "df = df.filter(df.relative_humidity_3pm.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Print the number of rows and columns in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1064\n",
      "Number of columns: 10\n"
     ]
    }
   ],
   "source": [
    "# print num rows in df\n",
    "print(\"Number of rows:\", df.count())\n",
    "# print num columns in df\n",
    "print(\"Number of columns:\", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Use \"Binarizer\" function to create a target categorical variable from the \"relative_humidity_3pm\" column. Name this target variable as \"label\". Specifically, if the humidity at 3pm is less than 25%, then we want the categorical value to be 0, otherwise the categorical value should be 1. Use \"24.99999\" for the threshold argument. Use \"relative_humidity_3pm\" for the inputCol argument. Use \"label\" for the outputCol argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=24.99999, inputCol=\"relative_humidity_3pm\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Apply the above \"binarizer\" tranformation to the input DataFrame to create a new DataFrame named \"binarizedDF\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizedDF = binarizer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. Look at the values of the first four rows in the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|relative_humidity_3pm|label|\n",
      "+---------------------+-----+\n",
      "|                36.16|  1.0|\n",
      "|           19.4265968|  0.0|\n",
      "|                14.46|  0.0|\n",
      "|          12.74254735|  0.0|\n",
      "+---------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that label worked\n",
    "binarizedDF.select(\"relative_humidity_3pm\", \"label\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Use \"VectorAssembler\" to aggregate the features which will be used to make predictions into a single column. Use \"featureColumns\" defined at step b for the inputCols argument. Use \"features\" for the outputCol argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### j. Apply the above assembler to the DataFrame binarizedDF to create a new DataFrame called \"assembled\" with the aggregated features in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled = assembler.transform(binarizedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k. Split the DataFrame \"assembled\" into \"train\" and \"test\" by calling randomSplit(). Specify the ratios of the two sets as 80% and 20%. Set the seed number to be 12345. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(12345)\n",
    "train, test = assembled.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### l. Print the number of rows in the train and test DataFrames to check the sizes. **NOTE**: if you get values that don't match the ratio, it is most likely due to the cluster's CPU configuration. It is OK for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 860 in the train dataset.\n",
      "There are 204 in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "trainCount = train.count()\n",
    "testCount = test.count()\n",
    "\n",
    "print(\"There are\", trainCount, \"in the train dataset.\")\n",
    "print(\"There are\", testCount, \"in the test dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m. Create and train decision tree. Use \"label\" as the labelCol argument. Use \"features\" as the  featuresCol argument. \n",
    "Also, set:\n",
    "* maxDepth = 5 - stopping criterion for tree induction based on maximum depth of tree\n",
    "* minInstancesPerNode = 20 - stopping criterion for tree induction based on minimum number of samples in a node\n",
    "* impurity = \"gini\" - the impurity measure used to split nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dtModel = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5, minInstancesPerNode=20, impurity=\"gini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedDt = dtModel.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### o. Make prediction using the test data set. Store the results in \"predictions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fittedDt.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p. Look at the values of \"prediction\" and \"label\" of the first ten rows in the predictions to see whether the prediction matches the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\",\"label\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q. Create an instance of MulticlassClassificationEvaluator to determine the accuracy of the predictions. Use \"label\" for the labelCol argument. Use \"prediction\" for the predictionCol argument. Use \"weightedPrecision\" for the metricName argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r. Compute the accuracy by calling evaluate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s. Print out the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918552036199095"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t. Display confusion matrix. The MulticlassMetrics class can be used to generate a confusion matrix of the classifier model. However, unlike MulticlassClassificationEvaluator, MulticlassMetrics works with RDDs of numbers and not DataFrames, so we need to convert our predictions DataFrame into an RDD. Let us try (**Done**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictions.select(\"prediction\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=1.0, label=1.0), Row(prediction=1.0, label=1.0)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### u. We can map the RDD to tuple to get an RDD of numbers (**Done**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsRdd = preds.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Create an instance of MulticlassMetrics with the RDD as created at the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcMetrics = MulticlassMetrics(predsRdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w. Use the confusionMatrix() function to get a Spark Matrix. Convert the matrix to a Python Numpy array by calling toArray(), and transpose to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75., 18.],\n",
       "       [25., 86.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcMetrics.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 Implementing a Recommender Using Spark MLlib\n",
    "This question uses a subset, movieslens.dat, of the Movielens dataset: https://grouplens.org/datasets/movielens/\n",
    "\n",
    "The Movielens data set captures movie ratings by user, along with user and movie attributes, and can be used for collaborative filtering. \n",
    "\n",
    "The dataset used in this question contains 100,000 ratings by 943 users on 1,682 items, with each user having rated at least 20 movies. \n",
    "\n",
    "The data movielens.dat is a tab-delimited, newline terminated text file with the following structure:\n",
    "\n",
    "user id\t| item id | rating | timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. First run the following cell to import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel, Rating\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Load the movielens.dat data into an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesRdd = spark.read.text(\"movielens.dat\").rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Show the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='196\\t242\\t3\\t881250949'),\n",
       " Row(value='186\\t302\\t3\\t891717742'),\n",
       " Row(value='22\\t377\\t1\\t878887116'),\n",
       " Row(value='244\\t51\\t2\\t880606923'),\n",
       " Row(value='166\\t346\\t1\\t886397596')]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Apply a sequence of map functions to the input RDD to create a new RDD called \"ratings\". The \"ratings\" RDD is a set of Rating objects. Each Rating object consists of three fields that correspond to the first three fields of the input RDD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = moviesRdd.map(lambda l: l.value.split('\\t'))\\\n",
    "    .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Train a collaborative filtering model by applying the imported ALS model to the \"ratings\" RDD. \n",
    "Set:\n",
    "* rank = 10\n",
    "* mumIterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 10\n",
    "\n",
    "model = ALS.train(ratings, rank, numIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Create a test data by using a map function to \"ratings\". The map function extracts the first two fields of the \"ratings\" RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ratings.map(lambda r: (r[0], r[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Show the values of first 5 rows of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(196, 242), (186, 302), (22, 377), (244, 51), (166, 346)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. Apply the model to the test data for prediction and store the results to \"predictions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predictAll(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Prepare the preditions to join with true ratings (**Done**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictions.map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((195, 1084), 4.038826602567418),\n",
       " ((58, 1084), 3.8508604359832006),\n",
       " ((541, 1084), 4.293768907459729)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### j. Join the predictions with the true ratings (**Done**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((196, 242), (3.0, 3.260025665083086)),\n",
       " ((186, 302), (3.0, 3.4392535752795967)),\n",
       " ((166, 346), (1.0, 1.945656412739603))]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratesAndPreds.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k. Compute and print the mean squared error from the RDD \"ratesAndPreds\". Specifically, compute the squared error for each pair of (rating, predition), sum up all the squared errors, and take the mean. The whole process can be done in one map function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4826230341753457"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
