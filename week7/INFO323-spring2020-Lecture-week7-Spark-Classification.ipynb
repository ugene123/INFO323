{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\"> INFO 323: Cloud Computing and Big Data</h1>\n",
    "<h2 style=\"text-align:center\"> College of Computing and Informatics</h2>\n",
    "<h2 style=\"text-align:center\">Drexel University</h2>\n",
    "\n",
    "<h3 style=\"text-align:center\">Lecture for Week 7</h3>\n",
    "<h3 style=\"text-align:center\"> Spark Classification (Definitive 26)</h3>\n",
    "<h3 style=\"text-align:center\"> Yuan An, PhD</h3>\n",
    "<h3 style=\"text-align:center\">Associate Professor</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models in MLlib\n",
    "Spark has several models available for performing binary and multiclass classification out of the box.\n",
    "The following models are available for classification in Spark:\n",
    "* Logistic regression\n",
    "* Decision trees\n",
    "* Random forests\n",
    "* Gradient-boosted trees\n",
    "\n",
    "Spark does not support making multilabel predictions natively. In order to train a multilabel model,\n",
    "you must train one model per label and combine them manually. Once manually constructed, there are\n",
    "built-in tools that support measuring these kinds of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start looking at the classification models by loading in some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bInput = spark.read.format(\"parquet\").load(\"gs://info323-ya45-spring2020-bucket/data/binary-classification\")\\\n",
    "  .selectExpr(\"features\", \"cast(label as double) as label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bInput.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bInput.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression\n",
    "Here’s a simple example using the LogisticRegression model. Notice how we didn’t specify any\n",
    "parameters because we’ll leverage the defaults and our data conforms to the proper column naming.\n",
    "In practice, you probably won’t need to change many of the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "print lr.explainParams() # see all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(bInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained you can get information about the model by taking a look at the coefficients\n",
    "and the intercept. The coefficients correspond to the individual feature weights (each feature weight\n",
    "is multiplied by each respective feature to compute the prediction) while the intercept is the value of\n",
    "the italics-intercept (if we chose to fit one when specifying the model). Seeing the coefficients can be\n",
    "helpful for inspecting the model that you built and comparing how features affect the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "print lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print lrModel.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "Logistic regression provides a model summary that gives you information about the final, trained\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "summary = lrModel.summary\n",
    "print summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.roc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.pr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed at which the model descends to the final result is shown in the objective history. We can\n",
    "access this through the objective history on the model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "summary.objectiveHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Here’s a minimal but complete example of using a decision tree classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "print dt.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtModel = dt.fit(bInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dt = dtModel.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and Gradient-Boosted Trees\n",
    "These methods are extensions of the decision tree. Rather than training one tree on all of the data, you\n",
    "train multiple trees on varying subsets of the data. The intuition behind doing this is that various\n",
    "decision trees will become “experts” in that particular domain while others become experts in others.\n",
    "By combining these various experts, you then get a “wisdom of the crowds” effect, where the group’s\n",
    "performance exceeds any individual. In addition, these methods can help prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rfClassifier = RandomForestClassifier()\n",
    "print rfClassifier.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel = rfClassifier.fit(bInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbtClassifier = GBTClassifier()\n",
    "print gbtClassifier.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel = gbtClassifier.fit(bInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "Naive Bayes classifiers are a collection of classifiers based on Bayes’ theorem. The core assumption\n",
    "behind the models is that all features in your data are independent of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes()\n",
    "print nb.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel = nb.fit(bInput.where(\"label != 0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation Metrics\n",
    "MLlib also contains tools that let you evaluate multiple classification metrics at once. Unfortunately,\n",
    "these metrics classes have not been ported over to Spark’s DataFrame-based ML package from the\n",
    "underlying RDD framework. So, at the time of this writing, you still have to create an RDD to use\n",
    "these. In the future, this functionality will likely be ported to DataFrames and the following may no\n",
    "longer be the best way to see metrics (although you will still be able to use these APIs).\n",
    "There are three different classification metrics we can use:\n",
    "* Binary classification metrics\n",
    "* Multiclass classification metrics\n",
    "* Multilabel classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "out = dtModel.transform(bInput)\\\n",
    "  .select(\"prediction\", \"label\")\\\n",
    "  .rdd.map(lambda x: (float(x[0]), float(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = BinaryClassificationMetrics(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we’ve done that, we can see typical classification success metrics on this metric’s object using\n",
    "a similar API to the one we saw with logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "print metrics.areaUnderPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print metrics.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Receiver Operating Characteristic\"\n",
    "metrics.roc.toDF().show()\n",
    "\n",
    "\n",
    "# COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
